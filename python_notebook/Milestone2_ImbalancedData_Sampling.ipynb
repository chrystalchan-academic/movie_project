{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: \n",
    "\n",
    "Discussion about the imbalanced nature of the data and how you want to address it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb_milestone2 = pd.read_csv(r\"C:\\Users\\cheriexu\\Downloads\\CS109B\\imdb_cluster_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>certificates_R</th>\n",
       "      <th>certificates_PG</th>\n",
       "      <th>art.direction_1</th>\n",
       "      <th>assistant.director_1</th>\n",
       "      <th>casting.director_1</th>\n",
       "      <th>cinematographer_1</th>\n",
       "      <th>costume.department_1</th>\n",
       "      <th>costume.designer_1</th>\n",
       "      <th>countries_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Action</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Musical</th>\n",
       "      <th>History</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Biography</th>\n",
       "      <th>cluster_response</th>\n",
       "      <th>genres_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322495</td>\n",
       "      <td>0.042103</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.046254</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Horror, Thriller, Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.093694</td>\n",
       "      <td>0.319431</td>\n",
       "      <td>0.165250</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.172860</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Romance, Comedy, Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212394</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Horror, Thriller, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.126112</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.536766</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Horror, Thriller, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104764</td>\n",
       "      <td>0.355406</td>\n",
       "      <td>0.017395</td>\n",
       "      <td>0.049812</td>\n",
       "      <td>0.126112</td>\n",
       "      <td>0.040028</td>\n",
       "      <td>0.536766</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Horror, Thriller, Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X  certificates_R  certificates_PG  art.direction_1  \\\n",
       "0    100               1                0         0.322495   \n",
       "1  10001               0                1         0.027673   \n",
       "2  10002               1                0         0.212394   \n",
       "3  10003               0                1         0.019767   \n",
       "4  10004               1                0         0.104764   \n",
       "\n",
       "   assistant.director_1  casting.director_1  cinematographer_1  \\\n",
       "0              0.042103            0.010279           0.046254   \n",
       "1              0.093694            0.319431           0.165250   \n",
       "2              0.024906            0.006523           0.016308   \n",
       "3              0.024906            0.014133           0.025301   \n",
       "4              0.355406            0.017395           0.049812   \n",
       "\n",
       "   costume.department_1  costume.designer_1  countries_1  \\\n",
       "0              0.307966            0.028662     0.089642   \n",
       "1              0.307966            0.172860     0.014232   \n",
       "2              0.012453            0.005535     0.089642   \n",
       "3              0.126112            0.007116     0.536766   \n",
       "4              0.126112            0.040028     0.536766   \n",
       "\n",
       "             ...             Action  Documentary  Musical  History  Family  \\\n",
       "0            ...                  0            0        0        0       0   \n",
       "1            ...                  0            0        0        1       0   \n",
       "2            ...                  0            0        0        0       0   \n",
       "3            ...                  1            0        0        0       0   \n",
       "4            ...                  0            0        0        0       0   \n",
       "\n",
       "   Fantasy  Sport  Biography  cluster_response               genres_comb  \n",
       "0        0      0          0                 5  Horror, Thriller, Action  \n",
       "1        0      0          0                 4  Romance, Comedy, Fantasy  \n",
       "2        0      0          0                 1   Horror, Thriller, Drama  \n",
       "3        0      0          0                 1   Horror, Thriller, Drama  \n",
       "4        1      0          0                 1   Horror, Thriller, Drama  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_milestone2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data set, we use \"cluster_response\" (i.e genre_comb) as our response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3621\n",
       "5    2641\n",
       "4    1953\n",
       "2    1850\n",
       "3      53\n",
       "Name: cluster_response, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_milestone2.ix[:,'cluster_response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By above frequency table, we can tell classes are not balanced in our processed data set. so we would like to do the following data sampling to deal with imbalanced sitaution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason for sampling :\n",
    "\n",
    "Imbalanced classes: most classification algorithms work relatively well on balanced classes where the number of samples of each class is similar. However, when some classes have outnumbered samples than others, there will be a difficulty solving classificiation problems with standard algorithms. Since these algorithms trend to minimize quantities such as error rate, they will more likely to predict towards the majority class. In order to minimize the problem caused by inbalanced classes, re-sampling the dataset as to offset the imbalance situation will be a pausible choice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Re-sampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three major types of re-sampling techniques:\n",
    "\n",
    "1. Under-sampling (the majority classes).\n",
    "\n",
    "2. Over-sampling (the minority classes).\n",
    "\n",
    "3. Combination of under-sampling & over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-sampling:\n",
    "\n",
    "**1. Randomly sample the majority class(es) samples with replacement:**\n",
    "\n",
    "    Set up a threshold to divide classes into minority classes and majority classes. Then randomly sample the movies in each majority class until the number of movies reach the average number of movies in the minority classes. When we sample with replacement, the two sample values are independent. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#possible useful package:\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cluster-based undersampling:**\n",
    "\n",
    "    cluster the majority classes samples to k clusters. Combine each cluster of majority class sample with all the minoirty class sample and make K combination of datasets. Classify all the datasets and choose the datasets out of K combined \n",
    "    datasets that gives the highest accuracy, regard it as the final training sample for building the decision support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible useful package & method:\n",
    "from imblearn.under_sampling import ClusterCentroids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper reference: http://www.iaeng.org/publication/WCE2013/WCE2013_pp1480-1485.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Nearest Neighbour based undersampling:**\n",
    "\n",
    "(1) condensed nearest neighbor rule (CNN):\n",
    "\n",
    "    select a sub-set A from the original data T which is consistent with T in the sense that A classifies T correctly with the one-nearest neighbor method. In specific, it starts from a set of data including all examples of the class of interest C and by removing examples and one randomly selected example from each class in rest of data O (= T - C), until without misclassifications.\n",
    "    \n",
    "    Drawbacks: extremely sensitive to noisy and many of them will be added to the training set. \n",
    "    \n",
    "(2) Edited nearest neighbor rule (ENN):\n",
    "\n",
    "    ENN removes examples whose class label differs from the majority class of the three nearest neighbors\n",
    "    \n",
    "(3) Neighborhood Cleaning rule:\n",
    "\n",
    "    Build on CNN and ENN, and identification and possible removal of outliers. \n",
    "    1. Split data T into the class of interest C and the rest of data O.\n",
    "    2. Identify noisy data A1 in O with the edited nearest neighbor rule.\n",
    "    3. For each class Ci in O, three nearest neighbors that misclassify examples are inserted into set A2. To avoid excessive reduction of small classes, only examples from classes larger or equal than 0.5 · | C | are considered while forming A2\n",
    "    4. Reduced data S = T - ( A1 ∪ A2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible useful package & method:\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import EditedNearestNeighbours \n",
    "from imblearn.under_sampling import CondensedNearestNeighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper reference: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.577.4704&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible issue of under-sampling is that if we have each combination of labels as a class, then there are possible many minority classes with few movies. Under-sampling majority classes may give us much fewer observations than the original data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Randomly sample the minority class(es) samples with replacement:**\n",
    "\n",
    "    Set up a threshold to divide classes into minority classes and majority classes. Then randomly sample the movies in each minority class until the number of movies reach the average number of movies in the majority classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible useful package & method:\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Synthetic Minority Over-sampling Technique - SMOTE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line\n",
    "segments joining any/all of the k minority class nearest neighbors. \n",
    "\n",
    "For instance, if the amount of over-sampling needed is 200%, only two neighbors from the five (if k=5) nearest neighbors\n",
    "are chosen and one sample is generated in the direction of each. Synthetic samples are generated in the following way: Take the difference between the feature vector (sample) under consideration and its nearest neighbor. Multiply this difference by a random number between 0 and 1, and add it to the feature vector under consideration. This causes the selection of a random point along the line segment between two specific features. This approach effectively forces the decision region of the minority class to become more general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible useful package & method:\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper reference: https://www.jair.org/media/953/live-953-2037-jair.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Adaptive synthetic sampling approach for imbalanced learning -ADASYN**\n",
    "\n",
    "It uses a density distribution as a criterion to automatically decide the number of synthetic samples that need to be generated for each minority data example. The density distribution is a measurement of the distribution of weights for different minority class examples according to their level of difficulty in learning. It provides different weights for different minority examples to compensate for the skewed distributions.\n",
    "\n",
    "Difference from SMOTE:  The resulting dataset post ADASYN will not only provide a balanced representation of the data distribution, but it will also force the learning algorithm to focus on those difficult to learn examples, where SMOTE has equal numbers of synthetic samples are generated for each minority data example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible useful package & method:\n",
    "from imblearn.over_sampling import ADASYN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper reference: http://ieeexplore.ieee.org/document/4633969/?tp=&arnumber=4633969&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4633969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One concern of over-sampling is that we already have large amount of data set, over-sampling will increase samples, which causes longer run-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of under-sampling & over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. First oversampling then undersampling: SMOTE (introduced in under-sampling) + Tomek links:**\n",
    "\n",
    "Frequently, class clusters are not well defined since some majority class examples might be invading the minority class space. The opposite can also be true, since interpolating minority class examples can expand the minority class clusters, introducing artificial minority class examples too deeply in the majority class space. Inducing a classifier under such a situation can lead to overfitting. In order to better-defined class clusters, we can apply Tomek links to the over-sampled training set as a data cleaning method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. First undersampling then oversampling: SMOTE (introduced in under-sampling) + ENN (introduced in over-sampling):**\n",
    "\n",
    "Similar to above, except ENN tends to remove more examples than the Tomek links does, so it is expected that it will provide a more in depth data cleaning.Thus, any example that is misclassified by its three nearest neighbors is removed from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper reference: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.7757&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "Three are benefits and drawbacks of each sampling methods. \n",
    "\n",
    "**Under-sampling**:\n",
    "\n",
    "Benefit:reduce sample size (lower runtime); more types of sampling methods.\n",
    "\n",
    "Drawbacks: much fewer observations than the original data set.\n",
    "\n",
    "**Over-sampling**\n",
    "\n",
    "Benefit:enough data set for each class.\n",
    "\n",
    "Drawbacks: even longer runtime.\n",
    "\n",
    "**Over-sampling and Under-sampling:**\n",
    "\n",
    "Benefit:avoid over-fitting by data cleaning.\n",
    "\n",
    "Drawbacks: not suitable for multiple classes.\n",
    "\n",
    "\n",
    "We can choose sampling method based on our final decision of the response variable, since some methods are not appliable to multi-class classification problems. However, if we would like to do the classificiation 1 by 1 (for example, Action movie vs Not Action movie), we can still use all of these methods. Right now, we would like to regard the response variable as a multi-class (each combination of labels/cluster as a class), we can only use sampling methods that are suitable for multiple classes.\n",
    "\n",
    "**Note: methods are applicable to multiple classes:**\n",
    "\n",
    "Under-sampling: (1) Random under-sampling (2) Condensed Nearest Neighbour (3) Edited nearest neighbor rule (4) Neighbourhood CleaningRule\n",
    "\n",
    "Over-sampling: (1) Random Over-sampling: Supports multiple classes. (2) SOMTE: It does not support multiple classes automatically, but can be called multiple times.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other  Useful References:\n",
    "\n",
    "Python class: imbalanced-learn: http://contrib.scikit-learn.org/imbalanced-learn/index.html\n",
    "\n",
    "Systematic Introducation of imbalanced classes (including evalution & after sampling algorithm level):  https://svds.com/learning-imbalanced-classes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions: \n",
    "How do you sample your data, how many samples, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large data set: IMDB and TMDB have large amounts movie data information available. Using all of them for the later model building will be computational challenge. Also, as we discussed earlier, there is an imbalanced class distribution in our dataset, so we would like to re-sampling data to solve the issue. Possible solution is using under-sampling to reduce the number of movies and resolve the imbalanced issue. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data example for re-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10118"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_milestone2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In milestone2, we didn't use all the movies due to longer than expected processing time to loading data, we use 10118 movies as example. In the later milestones, we will use all availble data set (after filtering movies does not meet our need). We estimated we will have more than 200,000 movies in the whole data set, so we would like to under-sampling larger classes to achieve a balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = imdb_milestone2.ix[:,\"X\":\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = imdb_milestone2.ix[:, \"cluster_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 3621, 5: 2641, 4: 1953, 2: 1850, 3: 53})\n"
     ]
    }
   ],
   "source": [
    "print('Resampled dataset shape {}'.format(Counter(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 53, 2: 53, 3: 53, 4: 53, 5: 53})\n"
     ]
    }
   ],
   "source": [
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 132, 2: 132, 4: 132, 5: 132, 3: 53})\n"
     ]
    }
   ],
   "source": [
    "#If we don't want the data set reduce too much, we can set a ratio\n",
    "rus = RandomUnderSampler(random_state=42, ratio = 0.4)\n",
    "X_res, y_res = rus.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import EditedNearestNeighbours \n",
    "from imblearn.under_sampling import CondensedNearestNeighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides random sampling, we can also use neighborhood based sampling methods, especially Neighborhood Cleaning rul. It combines the strength of Edited Nearest Neighbours and Condensed Nearest Neighbour, as we discussed ealier. However, it may gives us still an imbalanced classes if we set n_neighbors small. It also will decrease the number of observations in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 382, 3: 53, 5: 50, 2: 35, 4: 34})\n"
     ]
    }
   ],
   "source": [
    "ncr = NeighbourhoodCleaningRule(random_state=42,n_neighbors = 5)\n",
    "X_res, y_res = ncr.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to use either Random undersampling or CNN undersampling for the whole data set in the later milestones, based on how small the minority class is. Since CNN might drop the observation in the minority class, if we have very few observations in the minority class, we would like to use random sampling instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
