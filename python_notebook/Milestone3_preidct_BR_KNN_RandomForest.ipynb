{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrystal\\Anaconda2\\envs\\py27\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Chrystal\\Anaconda2\\envs\\py27\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.multiclass import LabelPowerSetClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_python_notebook = os.getcwd()\n",
    "dir_movie_project = os.path.abspath(os.path.join(dir_python_notebook, os.pardir))\n",
    "dir_data = os.path.join(dir_movie_project, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = dir_data + '//imdb_cluster_result_whole.csv'\n",
    "data_df= pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'certificates_R', u'certificates_PG', u'art.direction_1',\n",
       "       u'assistant.director_1', u'cinematographer_1', u'costume.department_1',\n",
       "       u'costume.designer_1', u'countries_1', u'director_1', u'distributors_1',\n",
       "       u'editor_1', u'languages_1', u'make.up_1', u'miscellaneous.companies_1',\n",
       "       u'miscellaneous.crew_1', u'original.music_1', u'producer_1',\n",
       "       u'production.companies_1', u'production.manager_1', u'sound.crew_1',\n",
       "       u'writer_1', u'special.effects.companies_1', u'cast_1', u'cast_2',\n",
       "       u'cast_3', u'cast_4', u'runtimes_avg', u'rating', u'imdb_id',\n",
       "       u'tmdb_id', u'Sci.Fi', u'Crime', u'Romance', u'Animation', u'Music',\n",
       "       u'Adult', u'Comedy', u'War', u'Horror', u'Film.Noir', u'Western',\n",
       "       u'News', u'Reality.TV', u'Thriller', u'Adventure', u'Mystery', u'Short',\n",
       "       u'Talk.Show', u'Drama', u'Action', u'Documentary', u'Musical',\n",
       "       u'History', u'Family', u'Fantasy', u'Game.Show', u'Sport', u'Biography',\n",
       "       u'cluster_response', u'cluster_1', u'cluster_2', u'cluster_3',\n",
       "       u'cluster_4', u'cluster_5', u'cluster_6', u'cluster_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['certificates_R',\n",
       " 'certificates_PG',\n",
       " 'art.direction_1',\n",
       " 'assistant.director_1',\n",
       " 'cinematographer_1',\n",
       " 'costume.department_1',\n",
       " 'costume.designer_1',\n",
       " 'countries_1',\n",
       " 'director_1',\n",
       " 'distributors_1',\n",
       " 'editor_1',\n",
       " 'languages_1',\n",
       " 'make.up_1',\n",
       " 'miscellaneous.companies_1',\n",
       " 'miscellaneous.crew_1',\n",
       " 'original.music_1',\n",
       " 'producer_1',\n",
       " 'production.companies_1',\n",
       " 'production.manager_1',\n",
       " 'sound.crew_1',\n",
       " 'writer_1',\n",
       " 'special.effects.companies_1',\n",
       " 'cast_1',\n",
       " 'cast_2',\n",
       " 'cast_3',\n",
       " 'cast_4',\n",
       " 'runtimes_avg',\n",
       " 'rating']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var= list(data_df.columns.values)\n",
    "X_var = X_var[0:28]\n",
    "X_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cluster_1',\n",
       " 'cluster_2',\n",
       " 'cluster_3',\n",
       " 'cluster_4',\n",
       " 'cluster_5',\n",
       " 'cluster_6',\n",
       " 'cluster_7']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_var = list(data_df.columns.values)\n",
    "Y_var = Y_var[59:66]\n",
    "Y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certificates_R</th>\n",
       "      <th>certificates_PG</th>\n",
       "      <th>art.direction_1</th>\n",
       "      <th>assistant.director_1</th>\n",
       "      <th>cinematographer_1</th>\n",
       "      <th>costume.department_1</th>\n",
       "      <th>costume.designer_1</th>\n",
       "      <th>countries_1</th>\n",
       "      <th>director_1</th>\n",
       "      <th>distributors_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Biography</th>\n",
       "      <th>cluster_response</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>cluster_3</th>\n",
       "      <th>cluster_4</th>\n",
       "      <th>cluster_5</th>\n",
       "      <th>cluster_6</th>\n",
       "      <th>cluster_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413003</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.085824</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   certificates_R  certificates_PG  art.direction_1  assistant.director_1  \\\n",
       "0               1                0         0.413003              0.000264   \n",
       "\n",
       "   cinematographer_1  costume.department_1  costume.designer_1  countries_1  \\\n",
       "0           0.000147              0.000015            0.000469     0.085824   \n",
       "\n",
       "   director_1  distributors_1    ...      Sport  Biography  cluster_response  \\\n",
       "0    0.000147        0.000103    ...          0          0                 2   \n",
       "\n",
       "   cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  \n",
       "0          0          0          0          1          0          1          0  \n",
       "\n",
       "[1 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input: dataframe from csv file\n",
    "#Output: y: response variable that is good for multi-label classification\n",
    "#        m: processor, may need to transform back in later\n",
    "def process_multilabel(dataframe):\n",
    "    #convert response variable to a set format\n",
    "    #for example, '\"Romance, \"Horror\"' to (\"Romance\", \"Horror\")\n",
    "    dataframe['genres_comb'] = dataframe['genres_comb'].apply(lambda x: eval(x))\n",
    "    y = dataframe.ix[:,'genres_comb']\n",
    "    m = MultiLabelBinarizer().fit(y)\n",
    "    y = m.transform(y)\n",
    "    return(y, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = data_df[data_df[u'tmdb_id'] < 50000]\n",
    "test_df = data_df[data_df[u'tmdb_id'] >= 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24326, 66)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "    \"hamming_loss\": hamming_loss,\n",
    "    \"subset_accuracy\": accuracy_score,\n",
    "    \"jaccard\": jaccard_similarity_score,\n",
    "    \"macro-f1\": partial(f1_score, average=\"macro\"),\n",
    "    \"samples-f1\": partial(f1_score, average=\"samples\"),\n",
    "    \"weighted-f1\": partial(f1_score, average=\"weighted\"),\n",
    "    \"micro-f1\": partial(f1_score, average=\"micro\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=0),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "    #\"SVM\": GridSearchCV(LinearSVC(random_state=0), scoring='f1',param_grid={\"C\": np.logspace(-5, -5, 20)}),\n",
    "    \"KNN, k=5\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"KNN, k=10\": KNeighborsClassifier(n_neighbors=10),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df[X_var]\n",
    "Y_true_train = train_df[Y_var]\n",
    "X_test = test_df[X_var]\n",
    "Y_true_test = test_df[Y_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrystal\\Anaconda2\\envs\\py27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metric_train = {}\n",
    "metric_test = {}\n",
    "for model_name, model in MODEL.items():\n",
    "    clf = OneVsRestClassifier(model)\n",
    "    clf.fit(X_train, Y_true_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    metric_train[model_name] = {} \n",
    "    metric_train[model_name][\"micro-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"micro\")\n",
    "    metric_train[model_name][\"weighted-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"weighted\")\n",
    "    metric_train[model_name][\"samples-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"samples\")\n",
    "    metric_train[model_name][\"macro-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"macro\")\n",
    "    metric_train[model_name][\"hamming_loss\"] = hamming_loss(Y_true_train, y_pred_train)\n",
    "    metric_train[model_name][\"subset_accuracy\"] = accuracy_score(Y_true_train, y_pred_train)\n",
    "    metric_train[model_name][\"jaccard\"] = jaccard_similarity_score(Y_true_train, y_pred_train)\n",
    "    \n",
    "    metric_test[model_name] = {} \n",
    "    metric_test[model_name][\"micro-f1\"] = f1_score(Y_true_test, y_pred_test, average=\"micro\")\n",
    "    metric_test[model_name][\"weighted-f1\"] = f1_score(Y_true_test, y_pred_test, average=\"weighted\")\n",
    "    metric_test[model_name][\"samples-f1\"] = f1_score(Y_true_test, y_pred_test, average=\"samples\")\n",
    "    metric_test[model_name][\"macro-f1\"] = f1_score(Y_true_test, y_pred_test, average=\"macro\")\n",
    "    metric_test[model_name][\"hamming_loss\"] = hamming_loss(Y_true_test, y_pred_test)\n",
    "    metric_test[model_name][\"subset_accuracy\"] = accuracy_score(Y_true_test, y_pred_test)\n",
    "    metric_test[model_name][\"jaccard\"] = jaccard_similarity_score(Y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, model in MODEL.items():\n",
    "    #print(model_name)\n",
    "    metric_test_df_new = pd.DataFrame.from_dict(metric_test[ model_name], orient='index').transpose()\n",
    "    metric_test_df_new['model'] = model_name\n",
    "    metric_test_df_new['strategy'] = \"One vs rest\"\n",
    "    try:\n",
    "        metric_test_df = metric_test_df.append(metric_test_df_new, ignore_index=True)\n",
    "    except:\n",
    "        metric_test_df = metric_test_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro-f1</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>samples-f1</th>\n",
       "      <th>subset_accuracy</th>\n",
       "      <th>weighted-f1</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539654</td>\n",
       "      <td>0.460998</td>\n",
       "      <td>0.343590</td>\n",
       "      <td>0.550919</td>\n",
       "      <td>0.222731</td>\n",
       "      <td>0.500538</td>\n",
       "      <td>0.216458</td>\n",
       "      <td>KNN, k=5</td>\n",
       "      <td>One vs rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.556560</td>\n",
       "      <td>0.486085</td>\n",
       "      <td>0.342994</td>\n",
       "      <td>0.562768</td>\n",
       "      <td>0.280324</td>\n",
       "      <td>0.492574</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>One vs rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.588820</td>\n",
       "      <td>0.532148</td>\n",
       "      <td>0.335847</td>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.316097</td>\n",
       "      <td>0.504393</td>\n",
       "      <td>0.175112</td>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>One vs rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.549086</td>\n",
       "      <td>0.484711</td>\n",
       "      <td>0.303238</td>\n",
       "      <td>0.562636</td>\n",
       "      <td>0.276835</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.191492</td>\n",
       "      <td>KNN, k=10</td>\n",
       "      <td>One vs rest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   micro-f1   jaccard  macro-f1  samples-f1  subset_accuracy  weighted-f1  \\\n",
       "0  0.539654  0.460998  0.343590    0.550919         0.222731     0.500538   \n",
       "1  0.556560  0.486085  0.342994    0.562768         0.280324     0.492574   \n",
       "2  0.588820  0.532148  0.335847    0.612360         0.316097     0.504393   \n",
       "3  0.549086  0.484711  0.303238    0.562636         0.276835     0.472725   \n",
       "\n",
       "   hamming_loss          model     strategy  \n",
       "0      0.216458       KNN, k=5  One vs rest  \n",
       "1      0.187398  Random Forest  One vs rest  \n",
       "2      0.175112    Extra Trees  One vs rest  \n",
       "3      0.191492      KNN, k=10  One vs rest  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As \"Extra Trees\" has the lowest hamming loss and the highest weighted-f1, it is the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
