{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of our performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel classification\n",
    "\n",
    "For our project, we have a multilabel classification problem involves mapping each movie in the dataset to a set of genre labels. In this type of classification problem, the labels are not mutually exclusive. For example, when classifying a movie into a set of genres, a single movie might be both Romance and Horror. Since the labels are not mutually exclusive, the predictions and true genre labels are now vectors of genre label sets, rather than vectors of genres. However, we can extend the fundamental ideas of precision, recall, etc. to operations on multilabel classification problems.\n",
    "\n",
    "Multilabel evaluation metrics are grouped into two main categories: example based and label based metrics. Example based metrics are computed individually for each instance, then averaged to obtain the final value. Label based metrics are computed per label, instead of per instance. There are two approaches called micro-averaging and macro-averaging. \n",
    "\n",
    "Let MLD be multilabel dataset, $D$ is the number of samples, $\\hat{y_j}$ is the predicted value for the $j$-th label sets of a given movie, $y_j$ is the corresponsing true label sets, and $n_{labels}$ is the number of labels.\n",
    "\n",
    "We can calculate different measurements and evalute by multiple measurements:\n",
    "\n",
    "**1. Compare bit-wise** . This can be too lenient, so we would not use it here.\n",
    "\n",
    "**2. Compare vector-ise** (Accuracy classification score). This can be too strict, so we would not focus on it.\n",
    "\n",
    "**3. Jaccard similarity score**: computes the average of Jaccard similarity coefficients (size of the intersection divided by the size of the union of two label sets) between pairs of label sets.\n",
    "\n",
    "$$Jaccard(\\hat{y_j},y_j) = \\frac{1}{|D|}\\sum_{j=1}^{|D|}\\frac{|\\hat{y_j}\\cap{y_j}|}{|\\hat{y_j}\\cup{y_j}|}$$\n",
    "\n",
    "**4. Hamming loss**. It is the most common evaluation metric in the multilabel literature, computed as the symmetric difference between predicted and true labels and divided by the total number of labels in the MLD.\n",
    "\n",
    "    Then Hamming loss $L_{Hamming}$ is defined as:\n",
    "\n",
    "$$L_{Hamming}(\\hat{y_j},y_j) = \\frac{1}{|D|}\\sum_{j=1}^{|D|}\\frac{xor(\\hat{y_j}, y_j)}{n_{labels}}$$\n",
    "\n",
    "The best value of Hamming loss is 0, the worst value of Hamming loss is 1.\n",
    "\n",
    "**5. mutil-label precision**: This metric is computed as the ratio of relevant labels predicted by the classifier.\n",
    "\n",
    "$$L_{precision}(\\hat{y_j},y_j) = \\frac{1}{|D|}\\sum_{j=1}^{|D|}\\frac{|\\hat{y_j}\\cap{y_j}|}{|{y_j}|}$$\n",
    "\n",
    "**6. multi-label recall**: It is a metric commonly used along with the previous one, measuring the proportion of predicted labels which are relevant.\n",
    "\n",
    "$$L_{recall}(\\hat{y_j},y_j) = \\frac{1}{|D|}\\sum_{j=1}^{|D|}\\frac{|\\hat{y_j}\\cap{y_j}|}{|\\hat{y_j}|}$$\n",
    "\n",
    "**7. F1 score (Harmonic Mean of precision and recall)**: providing a balanced assessment between precision\n",
    "and sensitivity\n",
    "\n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$ For multi-label case, this is the specified weighted average of the F1 score of each class. In specific, we can specify the average in following ways: 'micro' calculates metrics globally by counting the total true positives, false negatives and false positives, 'macro' calculates metrics for each label, and find their unweighted mean, and 'weighted' calculates metrics for each label, and find their average, weighted by support (the number of true instances for each label) to account for imbalance. \n",
    "\n",
    "If there are labels with more instances than others and if we want to bias our metric towards the most populated ones, we will use micro-average. If there are labels with more instances than others and if we want to bias your metric toward the least populated ones (or at least we don't want to bias toward the most populated ones), we will use macro-average. If the micro-average result is significantly lower than the macro-average one, it means that we have some gross misclassification in the most populated labels, whereas our smaller labels are probably correctly classified. If the macro-average result is significantly lower than the micro-average one, it means our smaller labels are poorly classified, whereas our larger ones are probably correctly classified. In terms of imbalance nature of data, we probably would like to use weighted-average to account for imbalance. The best value of F1 score is 1, the worst value of F1 score is 0.\n",
    "\n",
    "Based on the literature review, **Hamming loss** (best:0, worst:1) and **F1 score** (best:1, worst:0) are the suggested metrics for multi-label classification problems. We will evaluate above performance evaluations during the model building process, but with a focus on Hamming loss and F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of performance evaluation \n",
    "\n",
    "Actual performance evaluation will be included in other ipython notebooks, the following code is just easier for other teammates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>certificates_R</th>\n",
       "      <th>certificates_PG</th>\n",
       "      <th>art.direction_1</th>\n",
       "      <th>assistant.director_1</th>\n",
       "      <th>casting.director_1</th>\n",
       "      <th>cinematographer_1</th>\n",
       "      <th>costume.department_1</th>\n",
       "      <th>costume.designer_1</th>\n",
       "      <th>countries_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Action</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Musical</th>\n",
       "      <th>History</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Biography</th>\n",
       "      <th>cluster_response</th>\n",
       "      <th>genres_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322495</td>\n",
       "      <td>0.042103</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.046254</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Romance\", \"Comedy\", \"Fantasy\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.093694</td>\n",
       "      <td>0.319431</td>\n",
       "      <td>0.165250</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.172860</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>\"Horror\", \"Thriller\", \"Action\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212394</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Horror\", \"Thriller\", \"Drama\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.126112</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.536766</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Horror\", \"Thriller\", \"Drama\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104764</td>\n",
       "      <td>0.355406</td>\n",
       "      <td>0.017395</td>\n",
       "      <td>0.049812</td>\n",
       "      <td>0.126112</td>\n",
       "      <td>0.040028</td>\n",
       "      <td>0.536766</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Horror\", \"Thriller\", \"Drama\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X  certificates_R  certificates_PG  art.direction_1  \\\n",
       "0    100               1                0         0.322495   \n",
       "1  10001               0                1         0.027673   \n",
       "2  10002               1                0         0.212394   \n",
       "3  10003               0                1         0.019767   \n",
       "4  10004               1                0         0.104764   \n",
       "\n",
       "   assistant.director_1  casting.director_1  cinematographer_1  \\\n",
       "0              0.042103            0.010279           0.046254   \n",
       "1              0.093694            0.319431           0.165250   \n",
       "2              0.024906            0.006523           0.016308   \n",
       "3              0.024906            0.014133           0.025301   \n",
       "4              0.355406            0.017395           0.049812   \n",
       "\n",
       "   costume.department_1  costume.designer_1  countries_1  \\\n",
       "0              0.307966            0.028662     0.089642   \n",
       "1              0.307966            0.172860     0.014232   \n",
       "2              0.012453            0.005535     0.089642   \n",
       "3              0.126112            0.007116     0.536766   \n",
       "4              0.126112            0.040028     0.536766   \n",
       "\n",
       "                ...                Action  Documentary  Musical  History  \\\n",
       "0               ...                     0            0        0        0   \n",
       "1               ...                     0            0        0        1   \n",
       "2               ...                     0            0        0        0   \n",
       "3               ...                     1            0        0        0   \n",
       "4               ...                     0            0        0        0   \n",
       "\n",
       "   Family  Fantasy  Sport  Biography  cluster_response  \\\n",
       "0       0        0      0          0                 4   \n",
       "1       0        0      0          0                 5   \n",
       "2       0        0      0          0                 1   \n",
       "3       0        0      0          0                 1   \n",
       "4       0        1      0          0                 1   \n",
       "\n",
       "                      genres_comb  \n",
       "0  \"Romance\", \"Comedy\", \"Fantasy\"  \n",
       "1  \"Horror\", \"Thriller\", \"Action\"  \n",
       "2   \"Horror\", \"Thriller\", \"Drama\"  \n",
       "3   \"Horror\", \"Thriller\", \"Drama\"  \n",
       "4   \"Horror\", \"Thriller\", \"Drama\"  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For example purpose:\n",
    "imdb_example = pd.read_csv(r\"C:\\Users\\cheriexu\\Downloads\\CS109B\\movie_project\\r\\imdb_cluster_result.csv\")\n",
    "imdb_example.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input: dataframe from csv file\n",
    "#Output: y: response variable that is good for multi-label classification\n",
    "#        m: processor, may need to transform back in later\n",
    "def process_multilabel(dataframe):\n",
    "    #convert response variable to a set format\n",
    "    #for example, '\"Romance, \"Horror\"' to (\"Romance\", \"Horror\")\n",
    "    dataframe['genres_comb'] = dataframe['genres_comb'].apply(lambda x: eval(x))\n",
    "    y = dataframe.ix[:,'genres_comb']\n",
    "    m = MultiLabelBinarizer().fit(y)\n",
    "    y = m.transform(y)\n",
    "    return(y, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, m = process_multilabel(imdb_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (Romance, Comedy, Fantasy)\n",
       "1    (Horror, Thriller, Action)\n",
       "2     (Horror, Thriller, Drama)\n",
       "3     (Horror, Thriller, Drama)\n",
       "4     (Horror, Thriller, Drama)\n",
       "Name: genres_comb, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_example.ix[:,'genres_comb'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Comedy', 'Drama', 'Family',\n",
       "       'Fantasy', 'Horror', 'Music', 'Romance', 'Thriller'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for example purpose\n",
    "y_true_m = y[1:100]\n",
    "y_pred_m = y[101:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#two evluation functions:\n",
    "def f1score_evaluation(y_true_m, y_pred_m, average_method):\n",
    "    #convert  = [Horror, Thriller, Action] to a list with binary indication\n",
    "    #m = MultiLabelBinarizer().fit(y_true)\n",
    "    #f1score = f1_score(m.transform(y_true),\n",
    "    #     m.transform(y_pred),\n",
    "    #     average= average_method)\n",
    "    \n",
    "    return(f1_score(y_true_m, y_pred_m, average = average_method))\n",
    "\n",
    "def hammingloss_evaluation(y_true_m, y_pred_m):\n",
    "    #m = MultiLabelBinarizer().fit(y_true)\n",
    "    #hammingloss = hamming_loss(m.transform(y_true),\n",
    "    #     m.transform(y_pred))\n",
    "     return(hamming_loss(y_true_m,\n",
    "         y_pred_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49209799363385326"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score_evaluation(y_true_m, y_pred_m, 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2865013774104683"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hammingloss_evaluation(y_true_m, y_pred_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cross_val_score or GridSearchCV:\n",
    "\n",
    "f1 score with weighted average just set scoring ='f1_weighted' or:\n",
    "\n",
    "    eg:\n",
    "\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "    f1_scorer = make_scorer(f1score_evaluation, greater_is_better=Ture)\n",
    "    cross_val_score(clf, X, y, cv=3, scoring =f1_scorer)   \n",
    "\n",
    "hamming loss\n",
    "\n",
    "    hamming_scorer = make_scorer(hammingloss_evaluation, greater_is_better=False)\n",
    "    cross_val_score(clf, X, y, cv=3, scoring =hamming_scorer)   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python2.7]",
   "language": "python",
   "name": "conda-env-Python2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
