{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this python notebook, we use skmultilearn package as it focuses on multilabel classification. \n",
    "We  input the processeed data and use the training set to train the model and examine performance metrics for the test set.\n",
    "\n",
    "### Multi-label classification strategy\n",
    "We will use multi-label classification. Before we discuss which classifier to use (ex. KNN, SVM), we should consdier how we will treat the response variable first.\n",
    "\n",
    "The \"strategies\" we used is listed below:\n",
    "1. Binary Relevence(BR)\n",
    "we seperate each genre into seperate problems (one for each genre).\n",
    "However, this ignore label dependence. \n",
    "Ex. if a movie is tagged as Drama, it is likely that it is also tagged as Action. if a movie is tagged as  Horror, it is likely that it is also tagged as Romance.\n",
    "If two classes of a genre (Yes/No) have very uneven sizes in the training set, the classifier will lean toward the class with higher movie number.\n",
    "There is a method called a label correction strategy that can help to improve accuracy\n",
    "For example, if our prediction is [Y_horror, Y_romance, Y_drama]= [1,1,0], which does not really happen in training set. We find another likely matching vector. We may change our prediction to be [1,0,1].\n",
    "\n",
    "2. Classifier Chains (CC)\n",
    "We seperate each genre into seperate problems, but include previous predictions as predictors.\n",
    "For example, X is our predictor for Y_horror. Next, X, Y_horror are our predictor for Y_romance.\n",
    "However, error may be propagated down the chain.\n",
    "\n",
    "3. Label Powerset (LP)\n",
    "Instead of having seperate Y_i for each genre i, we will predict only Y. Y has 2^I possible values where I is the number of genre.\n",
    "For example, if Y_horror = 1, Y_romance = 0, Y_drama = 1, Y = [101]\n",
    "However, imbalance of the data can be an issue.\n",
    "\n",
    "### Classifier\n",
    "For each of the strategy, we will then apply different classifier.\n",
    "1. Naive Bayes\n",
    "2. KNN\n",
    "3. Multinomial\n",
    "4. SVM\n",
    "\n",
    "### Performance mertic\n",
    "Please refer to the python notebook \"Milestone3_performancemetrics\".\n",
    "In short, we will evaluate majorly based on F1 score and Hamming loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import math\n",
    "import seaborn.apionly as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance, LabelPowerset, ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.ensemble.rakeld import RakelD\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# classifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_python_notebook = os.getcwd()\n",
    "dir_movie_project = os.path.abspath(os.path.join(dir_python_notebook, os.pardir))\n",
    "dir_data = os.path.join(dir_movie_project, 'project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    #\"Random Forest\": RandomForestClassifier(random_state=0),\n",
    "    #\"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN, k=5\": KNeighborsClassifier(n_neighbors=5),\n",
    "    #\"KNN, k=10\": KNeighborsClassifier(n_neighbors=10),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STRATEGIES = {\n",
    "     'Binary Relevance': BinaryRelevance(),\n",
    "    'Classifier Chain': ClassifierChain(),\n",
    "    'Label Powerset': LabelPowerset()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## sample\n",
    "We originall have downloaded the movies with TMDB id from 1 to 300000. \n",
    "1. many id in between that range actually are not valid (There is no movie for that tmdb id)\n",
    "2. We only include movies that have data in both TMDB and IMDB.\n",
    "3. We exclude movies that have more than 50% of features missing.\n",
    "Overall, we have 68186 movies.\n",
    "\n",
    "## predictior variable\n",
    "1. We originally downloaded all 51 features from IMDB\n",
    "2. We removes features that have missing rate > 50% for the samples\n",
    "3. Some features has list of values, such as cast. As the list is ranked by columns, we convert \"cast\" to \"cast1\", \"cast2\", etc, so each column will only hold 1 value , instead of a list of values.\n",
    "4. We impute the missing data.\n",
    "5. We conver categorical variable such as \"certificates_R\" to relative frequency, so we can apply a lot of methods  that may only be suitable for numeric values.\n",
    "6. We select important features by methods like LASSO and Random Forest.\n",
    "Overall, we have 31 predictor variables.\n",
    "\n",
    "\n",
    "## response variable\n",
    "1. We use IMDB genre and convert it to 28 columns. They are binary. Ex. if movies has genre of \"Horror\" and \"Crime\", the relevent columns will be 1, else 0.\n",
    "2. Because 28 genres are too many, we decide to reduce the response variable by clustering with methods like K-mean, etc. We have 7 clusters. We also examine the cluster composition to ensure they make senese. Ex. 1 cluster include only \"Horror\" and \"Thriller\". 1 cluster includes \"Crime\", \"Mystery\",\"Film.Noir\".\n",
    "Overall, we have 7 response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = dir_data + '//imdb_cluster_result_whole.csv'\n",
    "data_df= pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68186, 66)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'certificates_R', u'certificates_PG', u'art.direction_1',\n",
       "       u'assistant.director_1', u'cinematographer_1', u'costume.department_1',\n",
       "       u'costume.designer_1', u'countries_1', u'director_1', u'distributors_1',\n",
       "       u'editor_1', u'languages_1', u'make.up_1', u'miscellaneous.companies_1',\n",
       "       u'miscellaneous.crew_1', u'original.music_1', u'producer_1',\n",
       "       u'production.companies_1', u'production.manager_1', u'sound.crew_1',\n",
       "       u'writer_1', u'special.effects.companies_1', u'cast_1', u'cast_2',\n",
       "       u'cast_3', u'cast_4', u'runtimes_avg', u'rating', u'imdb_id',\n",
       "       u'tmdb_id', u'Sci.Fi', u'Crime', u'Romance', u'Animation', u'Music',\n",
       "       u'Adult', u'Comedy', u'War', u'Horror', u'Film.Noir', u'Western',\n",
       "       u'News', u'Reality.TV', u'Thriller', u'Adventure', u'Mystery', u'Short',\n",
       "       u'Talk.Show', u'Drama', u'Action', u'Documentary', u'Musical',\n",
       "       u'History', u'Family', u'Fantasy', u'Game.Show', u'Sport', u'Biography',\n",
       "       u'cluster_response', u'cluster_1', u'cluster_2', u'cluster_3',\n",
       "       u'cluster_4', u'cluster_5', u'cluster_6', u'cluster_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "['certificates_R', 'certificates_PG', 'art.direction_1', 'assistant.director_1', 'cinematographer_1', 'costume.department_1', 'costume.designer_1', 'countries_1', 'director_1', 'distributors_1', 'editor_1', 'languages_1', 'make.up_1', 'miscellaneous.companies_1', 'miscellaneous.crew_1', 'original.music_1', 'producer_1', 'production.companies_1', 'production.manager_1', 'sound.crew_1', 'writer_1', 'special.effects.companies_1', 'cast_1', 'cast_2', 'cast_3', 'cast_4', 'runtimes_avg', 'rating']\n"
     ]
    }
   ],
   "source": [
    "X_var= list(data_df.columns.values)\n",
    "X_var = X_var[0:28]\n",
    "print(len(X_var))\n",
    "print(X_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6', 'cluster_7']\n"
     ]
    }
   ],
   "source": [
    "Y_var = list(data_df.columns.values)\n",
    "Y_var = Y_var[59:66]\n",
    "print(len(Y_var))\n",
    "print(Y_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metric_data_frame(Y_true_train, y_pred_train,train, model_name, strategy):\n",
    "    metric_train = {} \n",
    "    metric_train[\"micro-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"micro\")\n",
    "    metric_train[\"weighted-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"weighted\")\n",
    "    metric_train[\"samples-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"samples\")\n",
    "    metric_train[\"macro-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"macro\")\n",
    "    metric_train[\"hamming_loss\"] = hamming_loss(Y_true_train, y_pred_train)\n",
    "    metric_train[\"subset_accuracy\"] = accuracy_score(Y_true_train, y_pred_train)\n",
    "    metric_train[\"jaccard\"] = jaccard_similarity_score(Y_true_train, y_pred_train)\n",
    "    \n",
    "    metric_test_df_new = pd.DataFrame.from_dict(metric_train, orient='index').transpose()\n",
    "    metric_test_df_new['model'] = model_name\n",
    "    metric_test_df_new['strategy'] = strategy\n",
    "    metric_test_df_new['train_test'] = train\n",
    "    \n",
    "    return metric_test_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predicion_result(X_train, Y_true_train, X_test, Y_true_test, strategy, model, model_name ):\n",
    "  \n",
    "    clf = BinaryRelevance(model)\n",
    "    if (strategy == \"Classifier Chain\"):\n",
    "        clf = ClassifierChain(model)\n",
    "    if (strategy == \"Label Powerset\"):\n",
    "        clf = LabelPowerset(model)   \n",
    "    # train\n",
    "    clf.fit(X_train, Y_true_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "\n",
    "    metric_df = get_metric_data_frame(Y_true_train, y_pred_train, \"train\", model_name, strategy)\n",
    "    metric_df  = metric_df.append(get_metric_data_frame(Y_true_test, y_pred_test, \"test\", model_name, strategy), ignore_index=True)\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X_train, Y_true_train, X_test, Y_true_test, model_name_list, strategy_list):\n",
    "    count = 0\n",
    "    for i in range(len(model_name_list)):\n",
    "        model_name = model_name_list[i]\n",
    "        model = MODELS[model_name]\n",
    "        for strategy in strategy_list:\n",
    "\n",
    "            metric_df_new = get_predicion_result(X_train, Y_true_train, X_test, Y_true_test,strategy, model, model_name )\n",
    "            if count > 0 :\n",
    "                metric_df = metric_df.append(metric_df_new, ignore_index=True)\n",
    "            else: \n",
    "                metric_df = metric_df_new\n",
    "            \n",
    "            count = count + 1\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "We examinf KNN and SVM.\n",
    "To use the prediction methods, plesae add the new model and the optimal parameter in the dictionary MODELS.\n",
    "\n",
    "### Resource\n",
    "Cross validation example from scikit-multilearn:\n",
    "http://scikit.ml/api/loading.html#cross-validation-and-train-test-splits\n",
    "\n",
    "\n",
    "Tuning parameter example from scikit-multilearn:\n",
    "http://scikit.ml/api/model_estimation.html#estimating-hyper-parameter-k-for-embedded-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = data_df[data_df[u'tmdb_id'] < 100000]\n",
    "test_df = data_df[data_df[u'tmdb_id'] >= 100000]\n",
    "X_train = train_df[X_var]\n",
    "Y_true_train = train_df[Y_var]\n",
    "X_test = test_df[X_var]\n",
    "Y_true_test = test_df[Y_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_neighbors',\n",
       " 'n_jobs',\n",
       " 'algorithm',\n",
       " 'metric',\n",
       " 'metric_params',\n",
       " 'p',\n",
       " 'weights',\n",
       " 'leaf_size']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out what parameters can we tune\n",
    "KNeighborsClassifier().get_params().keys()\n",
    "\n",
    "# I choose to only tune n_neightbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labelset_size': 7, 'classifier__classifier': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'), 'classifier': BinaryRelevance(classifier=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'),\n",
      "        require_dense=[True, True]), 'classifier__classifier__n_neighbors': 1} 0.365419276444\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'labelset_size': [7],\n",
    "    'classifier': [BinaryRelevance()],\n",
    "    'classifier__classifier': [KNeighborsClassifier()],\n",
    "    'classifier__classifier__n_neighbors': [1, 9],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RakelD(), parameters, scoring='f1_macro')\n",
    "clf.fit(X_train, Y_true_train)\n",
    "\n",
    "print clf.best_params_, clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labelset_size': 7, 'classifier__classifier': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'), 'classifier': ClassifierChain(classifier=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'),\n",
      "        require_dense=[True, True]), 'classifier__classifier__n_neighbors': 1} 0.365419276444\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'labelset_size': [7],\n",
    "    'classifier': [ClassifierChain()],\n",
    "    'classifier__classifier': [KNeighborsClassifier()],\n",
    "    'classifier__classifier__n_neighbors': [1, 9],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RakelD(), parameters, scoring='f1_macro')\n",
    "clf.fit(X_train, Y_true_train)\n",
    "\n",
    "print clf.best_params_, clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labelset_size': 7, 'classifier__classifier': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'), 'classifier': LabelPowerset(classifier=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'),\n",
      "       require_dense=[True, True]), 'classifier__classifier__n_neighbors': 1} 0.365419276444\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'labelset_size': [7],\n",
    "    'classifier': [LabelPowerset()],#[LabelPowerset(), BinaryRelevance()],\n",
    "    'classifier__classifier': [KNeighborsClassifier()],\n",
    "    'classifier__classifier__n_neighbors': [1, 9],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RakelD(), parameters, scoring='f1_macro')\n",
    "clf.fit(X_train, Y_true_train)\n",
    "\n",
    "print clf.best_params_, clf.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smaller dataset was used here for tuning as it took too much time tuning whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kernel',\n",
       " 'C',\n",
       " 'verbose',\n",
       " 'probability',\n",
       " 'degree',\n",
       " 'shrinking',\n",
       " 'max_iter',\n",
       " 'decision_function_shape',\n",
       " 'random_state',\n",
       " 'tol',\n",
       " 'cache_size',\n",
       " 'coef0',\n",
       " 'gamma',\n",
       " 'class_weight']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = data_df[data_df[u'tmdb_id'] < 10000]\n",
    "X_train1 = df_new[X_var]\n",
    "Y_true_train1 = df_new[Y_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aixu/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__classifier__gamma': 0.1, 'labelset_size': 7, 'classifier__classifier': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier': BinaryRelevance(classifier=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "        require_dense=[True, True]), 'classifier__classifier__C': 100} 0.369298212185\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'labelset_size': [7],\n",
    "    'classifier': [BinaryRelevance()],\n",
    "    'classifier__classifier': [SVC()],\n",
    "    'classifier__classifier__C': [1, 10, 100],\n",
    "    'classifier__classifier__gamma': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RakelD(), parameters, scoring='f1_macro')\n",
    "clf.fit(X_train1, Y_true_train1)\n",
    "\n",
    "print clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__classifier__gamma': 0.1, 'labelset_size': 7, 'classifier__classifier': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier': ClassifierChain(classifier=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "        require_dense=[True, True]), 'classifier__classifier__C': 100} 0.391546701311\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'labelset_size': [7],\n",
    "    'classifier': [ClassifierChain()],\n",
    "    'classifier__classifier': [SVC()],\n",
    "    'classifier__classifier__C': [1, 10, 100],\n",
    "    'classifier__classifier__gamma': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RakelD(), parameters, scoring='f1_macro')\n",
    "clf.fit(X_train1, Y_true_train1)\n",
    "\n",
    "print clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__classifier__gamma': 0.1, 'labelset_size': 7, 'classifier__classifier': SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'classifier': LabelPowerset(classifier=SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       require_dense=[True, True]), 'classifier__classifier__C': 100} 0.39160233552\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'labelset_size': [7],\n",
    "    'classifier': [LabelPowerset()],\n",
    "    'classifier__classifier': [SVC()],\n",
    "    'classifier__classifier__C': [1, 10, 100],\n",
    "    'classifier__classifier__gamma': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RakelD(), parameters, scoring='f1_macro')\n",
    "clf.fit(X_train1, Y_true_train1)\n",
    "\n",
    "print clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After tuning, we input the variable below\n",
    "\n",
    "MODELS = {\n",
    "    #\"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    #\"Random Forest\": RandomForestClassifier(random_state=0),\n",
    "    #\"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "    \"SVM C=100 gamma=0.1\": SVC(C=100, gamma=0.1),\n",
    "    \"KNN k=1\": KNeighborsClassifier(n_neighbors=1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "\n",
    "We tried both traditional k fold and stratified k fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validate_by_kfold(data_df, X_var, Y_var, n_split):\n",
    "    count = 0\n",
    "    # remember to set n_splits and shuffle!\n",
    "    kf = KFold(n_splits=n_split, random_state=None, shuffle= True)\n",
    "\n",
    "    X = data_df[X_var]\n",
    "    Y = data_df[Y_var]\n",
    "\n",
    "    for train_index, test_index in kf.split(X, Y):\n",
    "        X_train = X.iloc[train_index]\n",
    "        Y_true_train = Y.iloc[train_index]\n",
    "\n",
    "        X_test = X.iloc[test_index]\n",
    "        Y_true_test = Y.iloc[test_index]\n",
    "        \n",
    "        model_name_list = MODELS.keys()       \n",
    "        \n",
    "        strategy_list = STRATEGIES.keys()\n",
    "        \n",
    "        metric_df_new = predict(X_train, Y_true_train, X_test, Y_true_test, model_name_list, strategy_list)\n",
    "\n",
    "        if count == 0 :\n",
    "            metric_df = metric_df_new\n",
    "        else:\n",
    "            metric_df = metric_df.append(metric_df_new, ignore_index=True)\n",
    "        count = count + 1\n",
    "        \n",
    "    metric_grouped_df = metric_df.groupby(['model','strategy','train_test']).mean().reset_index()\n",
    "        \n",
    "    return metric_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validate_by_stratifiedkfold(data_df, X_var, Y_var, n_split):\n",
    "    count = 0\n",
    "\n",
    "    strategy_list = STRATEGIES.keys()\n",
    "    \n",
    "    for strategy in strategy_list:\n",
    "\n",
    "        sc = STRATEGIES[strategy]\n",
    "\n",
    "        # remember to set n_splits and shuffle!\n",
    "        kf = StratifiedKFold(n_splits=n_split, random_state=None, shuffle=True)\n",
    "\n",
    "        X = data_df[X_var]\n",
    "        Y = data_df[Y_var]\n",
    "\n",
    "\n",
    "        for train_index, test_index in kf.split(X, sc.transform(Y)):\n",
    "\n",
    "            X_train = X.iloc[train_index]\n",
    "            Y_true_train = Y.iloc[train_index]\n",
    "\n",
    "            X_test = X.iloc[test_index]\n",
    "            Y_true_test = Y.iloc[test_index]\n",
    "\n",
    "            model_name_list = MODELS.keys()       \n",
    "\n",
    "            #strategy_list = STRATEGIES.keys()\n",
    "            strategy_list = [strategy]\n",
    "\n",
    "            metric_df_new = predict(X_train, Y_true_train, X_test, Y_true_test, model_name_list, strategy_list)\n",
    "\n",
    "            if count == 0 :\n",
    "                metric_df = metric_df_new\n",
    "            else:\n",
    "                metric_df = metric_df.append(metric_df_new, ignore_index=True)\n",
    "                \n",
    "            count = count + 1\n",
    "        \n",
    "    metric_grouped_df = metric_df.groupby(['model','strategy','train_test']).mean().reset_index()\n",
    "    \n",
    "    return metric_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aixu/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>train_test</th>\n",
       "      <th>micro-f1</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>samples-f1</th>\n",
       "      <th>subset_accuracy</th>\n",
       "      <th>weighted-f1</th>\n",
       "      <th>hamming_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN k=1</td>\n",
       "      <td>Binary Relevance</td>\n",
       "      <td>test</td>\n",
       "      <td>0.510624</td>\n",
       "      <td>0.391650</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>0.503316</td>\n",
       "      <td>0.096902</td>\n",
       "      <td>0.510029</td>\n",
       "      <td>0.319744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN k=1</td>\n",
       "      <td>Binary Relevance</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN k=1</td>\n",
       "      <td>Classifier Chain</td>\n",
       "      <td>test</td>\n",
       "      <td>0.510624</td>\n",
       "      <td>0.391650</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>0.503316</td>\n",
       "      <td>0.096902</td>\n",
       "      <td>0.510029</td>\n",
       "      <td>0.319744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN k=1</td>\n",
       "      <td>Classifier Chain</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN k=1</td>\n",
       "      <td>Label Powerset</td>\n",
       "      <td>test</td>\n",
       "      <td>0.510624</td>\n",
       "      <td>0.391650</td>\n",
       "      <td>0.402783</td>\n",
       "      <td>0.503316</td>\n",
       "      <td>0.096902</td>\n",
       "      <td>0.510029</td>\n",
       "      <td>0.319744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN k=1</td>\n",
       "      <td>Label Powerset</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM C=100 gamma=0.1</td>\n",
       "      <td>Binary Relevance</td>\n",
       "      <td>test</td>\n",
       "      <td>0.540903</td>\n",
       "      <td>0.435450</td>\n",
       "      <td>0.375128</td>\n",
       "      <td>0.546143</td>\n",
       "      <td>0.142924</td>\n",
       "      <td>0.501887</td>\n",
       "      <td>0.269625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM C=100 gamma=0.1</td>\n",
       "      <td>Binary Relevance</td>\n",
       "      <td>train</td>\n",
       "      <td>0.764034</td>\n",
       "      <td>0.679070</td>\n",
       "      <td>0.690161</td>\n",
       "      <td>0.756678</td>\n",
       "      <td>0.438367</td>\n",
       "      <td>0.744999</td>\n",
       "      <td>0.139149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM C=100 gamma=0.1</td>\n",
       "      <td>Classifier Chain</td>\n",
       "      <td>test</td>\n",
       "      <td>0.533869</td>\n",
       "      <td>0.427875</td>\n",
       "      <td>0.408516</td>\n",
       "      <td>0.536703</td>\n",
       "      <td>0.138993</td>\n",
       "      <td>0.520522</td>\n",
       "      <td>0.291132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM C=100 gamma=0.1</td>\n",
       "      <td>Classifier Chain</td>\n",
       "      <td>train</td>\n",
       "      <td>0.771846</td>\n",
       "      <td>0.713282</td>\n",
       "      <td>0.724794</td>\n",
       "      <td>0.771515</td>\n",
       "      <td>0.548161</td>\n",
       "      <td>0.766200</td>\n",
       "      <td>0.142353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM C=100 gamma=0.1</td>\n",
       "      <td>Label Powerset</td>\n",
       "      <td>test</td>\n",
       "      <td>0.525668</td>\n",
       "      <td>0.417097</td>\n",
       "      <td>0.401248</td>\n",
       "      <td>0.526473</td>\n",
       "      <td>0.127433</td>\n",
       "      <td>0.514927</td>\n",
       "      <td>0.300714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM C=100 gamma=0.1</td>\n",
       "      <td>Label Powerset</td>\n",
       "      <td>train</td>\n",
       "      <td>0.872443</td>\n",
       "      <td>0.838968</td>\n",
       "      <td>0.853376</td>\n",
       "      <td>0.870157</td>\n",
       "      <td>0.754972</td>\n",
       "      <td>0.870817</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model          strategy train_test  micro-f1   jaccard  \\\n",
       "0               KNN k=1  Binary Relevance       test  0.510624  0.391650   \n",
       "1               KNN k=1  Binary Relevance      train  1.000000  1.000000   \n",
       "2               KNN k=1  Classifier Chain       test  0.510624  0.391650   \n",
       "3               KNN k=1  Classifier Chain      train  1.000000  1.000000   \n",
       "4               KNN k=1    Label Powerset       test  0.510624  0.391650   \n",
       "5               KNN k=1    Label Powerset      train  1.000000  1.000000   \n",
       "6   SVM C=100 gamma=0.1  Binary Relevance       test  0.540903  0.435450   \n",
       "7   SVM C=100 gamma=0.1  Binary Relevance      train  0.764034  0.679070   \n",
       "8   SVM C=100 gamma=0.1  Classifier Chain       test  0.533869  0.427875   \n",
       "9   SVM C=100 gamma=0.1  Classifier Chain      train  0.771846  0.713282   \n",
       "10  SVM C=100 gamma=0.1    Label Powerset       test  0.525668  0.417097   \n",
       "11  SVM C=100 gamma=0.1    Label Powerset      train  0.872443  0.838968   \n",
       "\n",
       "    macro-f1  samples-f1  subset_accuracy  weighted-f1  hamming_loss  \n",
       "0   0.402783    0.503316         0.096902     0.510029      0.319744  \n",
       "1   1.000000    1.000000         1.000000     1.000000      0.000000  \n",
       "2   0.402783    0.503316         0.096902     0.510029      0.319744  \n",
       "3   1.000000    1.000000         1.000000     1.000000      0.000000  \n",
       "4   0.402783    0.503316         0.096902     0.510029      0.319744  \n",
       "5   1.000000    1.000000         1.000000     1.000000      0.000000  \n",
       "6   0.375128    0.546143         0.142924     0.501887      0.269625  \n",
       "7   0.690161    0.756678         0.438367     0.744999      0.139149  \n",
       "8   0.408516    0.536703         0.138993     0.520522      0.291132  \n",
       "9   0.724794    0.771515         0.548161     0.766200      0.142353  \n",
       "10  0.401248    0.526473         0.127433     0.514927      0.300714  \n",
       "11  0.853376    0.870157         0.754972     0.870817      0.081249  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with a smaller data set to ensure the method works\n",
    "data_df_new = data_df[data_df[u'tmdb_id'] < 10000]\n",
    "count = 0\n",
    "# remember to set n_splits and shuffle!\n",
    "n_split=5\n",
    "kf = KFold(n_splits=n_split, random_state=None, shuffle= True)\n",
    "\n",
    "X = data_df_new[X_var]\n",
    "Y = data_df_new[Y_var]\n",
    "\n",
    "for train_index, test_index in kf.split(X, Y):\n",
    "    X_train = X.iloc[train_index]\n",
    "    Y_true_train = Y.iloc[train_index]\n",
    "\n",
    "    X_test = X.iloc[test_index]\n",
    "    Y_true_test = Y.iloc[test_index]\n",
    "\n",
    "    model_name_list = MODELS.keys()       \n",
    "\n",
    "    strategy_list = STRATEGIES.keys()\n",
    "\n",
    "    metric_df_new = predict(X_train, Y_true_train, X_test, Y_true_test, model_name_list, strategy_list)\n",
    "\n",
    "    if count == 0 :\n",
    "        metric_df = metric_df_new\n",
    "    else:\n",
    "        metric_df = metric_df.append(metric_df_new, ignore_index=True)\n",
    "    count = count + 1\n",
    "\n",
    "metric_grouped_df = metric_df.groupby(['model','strategy','train_test']).mean().reset_index()\n",
    "metric_grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use **weighted-f1** and **hamming_loss** as our final performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metric_data_frame(Y_true_train, y_pred_train,train, model_name, strategy):\n",
    "    metric_train = {} \n",
    "    \n",
    "    metric_train[\"weighted-f1\"] = f1_score(Y_true_train, y_pred_train, average=\"weighted\")\n",
    "    metric_train[\"hamming_loss\"] = hamming_loss(Y_true_train, y_pred_train)\n",
    "    \n",
    "    metric_test_df_new = pd.DataFrame.from_dict(metric_train, orient='index').transpose()\n",
    "    metric_test_df_new['model'] = model_name\n",
    "    metric_test_df_new['strategy'] = strategy\n",
    "    metric_test_df_new['train_test'] = train\n",
    "    \n",
    "    return metric_test_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test \n",
    "n_split = 5\n",
    "metric_df_kfold  = cross_validate_by_kfold(data_df_new, X_var, Y_var, n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_df_stratifiedkfold  = cross_validate_by_kfold(data_df_new, X_var, Y_var, n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_df_kfold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_df_stratifiedkfold.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_metric_for_strategy(train_test, strategy, metric):\n",
    "    title = metric + \" for \" + strategy\n",
    "    metric_plot_df = metric_df[(metric_df['strategy']== strategy) & (metric_df['train_test']== train_test)]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "    ax = sns.barplot(x=\"model\", y=metric, data=metric_plot_df)\n",
    "    xt = plt.xticks(rotation=90)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_metric_for_strategy(\"test\",\"Binary Relevance\",\"hamming_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_df = metric_df_stratifiedkfold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_metric_for_strategy(\"test\",\"Classifier Chain\",\"hamming_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_metric_for_strategy(\"test\",\"Label Powerset\",\"hamming_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_metric_for_strategy(\"test\",\"Binary Relevance\",\"weighted-f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_metric_for_strategy(\"test\",\"Classifier Chain\",\"weighted-f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_metric_for_strategy(\"test\",\"Label Powerset\",\"weighted-f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results and Discussion\n",
    "\n",
    "## Goal\n",
    "\n",
    "1. We examine the performance metric for the test set among various classifiers.\n",
    "    - For hamming loss, the smaller the value , the smaller the difference between predicted and true labels.\n",
    "\n",
    "    - For F1 score, the larger the value , the smaller the difference between predicted and true labels. We will focus on weighted F1 score for now.\n",
    "\n",
    "2. We examine the performance metric for each strategy :Binary Relevance,Classifier Chain,Label Powerset.\n",
    "\n",
    "3. We will look into the performance metric for labels with more movies vs labels with fewer moviews.\n",
    "    - We can examine the difference between F1 score for macro average and micro average. If the micro-average result is significantly lower than the macro-average one, it means that we have some gross misclassification in the most populated labels, whereas our smaller labels are probably correctly classified. \n",
    "    \n",
    "4. We examine if cross-validation by kfold has similiar result as by stratified kfold\n",
    "    - k-folding may lead to severe problems with label combination representability across folds, thus if the data exhibits a strong label co-occurrence structure,  using a label-combination based stratified k-fold will be better.\n",
    "    \n",
    "\n",
    "## 1.  Classifier with the best metric\n",
    "XXXXXXX\n",
    "\n",
    "## 2.  Strategy with the best metric\n",
    "XXXXXXXXXX\n",
    "\n",
    "## 3.  If the best method we pick favor any label of size differences\n",
    "XXXXXXXXXxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
